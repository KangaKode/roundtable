"""Unit tests for the learning module -- feedback, trust, check-ins, profile."""

import pytest
from src.{{project_slug}}.learning.models import FeedbackSignal, UserPreference, SignalType, CheckInStatus
from src.{{project_slug}}.learning.feedback_tracker import FeedbackTracker
from src.{{project_slug}}.learning.agent_trust import AgentTrustManager, DEFAULT_TRUST, TRUST_FLOOR, TRUST_CEILING
from src.{{project_slug}}.learning.checkin_manager import CheckInManager
from src.{{project_slug}}.learning.user_profile import UserProfileManager


class TestFeedbackTracker:
    def test_record_returns_signal_with_id(self, learning_db):
        tracker = FeedbackTracker(db_path=learning_db)
        signal = FeedbackSignal(signal_type="accept", agent_id="agent_a")
        result = tracker.record(signal)
        assert result.id is not None
        assert result.signal_type == "accept"

    def test_get_signals_filters_by_agent(self, learning_db):
        tracker = FeedbackTracker(db_path=learning_db)
        tracker.record(FeedbackSignal(signal_type="accept", agent_id="agent_a"))
        tracker.record(FeedbackSignal(signal_type="reject", agent_id="agent_b"))

        signals = tracker.get_signals(agent_id="agent_a")
        assert len(signals) == 1
        assert signals[0].agent_id == "agent_a"

    def test_get_signals_filters_by_type(self, learning_db):
        tracker = FeedbackTracker(db_path=learning_db)
        tracker.record(FeedbackSignal(signal_type="accept", agent_id="agent_a"))
        tracker.record(FeedbackSignal(signal_type="reject", agent_id="agent_a"))

        signals = tracker.get_signals(signal_type="accept")
        assert all(s.signal_type == "accept" for s in signals)

    def test_get_signal_counts(self, learning_db):
        tracker = FeedbackTracker(db_path=learning_db)
        for _ in range(3):
            tracker.record(FeedbackSignal(signal_type="accept", agent_id="a"))
        for _ in range(2):
            tracker.record(FeedbackSignal(signal_type="reject", agent_id="a"))

        counts = tracker.get_signal_counts()
        assert counts["accept"] == 3
        assert counts["reject"] == 2

    def test_get_acceptance_rates(self, learning_db):
        tracker = FeedbackTracker(db_path=learning_db)
        for _ in range(3):
            tracker.record(FeedbackSignal(signal_type="accept", agent_id="agent_a"))
        tracker.record(FeedbackSignal(signal_type="reject", agent_id="agent_a"))

        rates = tracker.get_acceptance_rates()
        assert "agent_a" in rates
        assert rates["agent_a"] == pytest.approx(0.75, abs=0.01)


class TestAgentTrustManager:
    def test_default_trust_for_unknown(self, learning_db):
        mgr = AgentTrustManager(db_path=learning_db)
        assert mgr.get_trust("unknown_agent") == DEFAULT_TRUST

    def test_accept_increases_trust(self, learning_db):
        mgr = AgentTrustManager(db_path=learning_db)
        signal = FeedbackSignal(signal_type=SignalType.ACCEPT, agent_id="agent_a")
        result = mgr.update_from_signal(signal)
        assert result.trust_score > DEFAULT_TRUST

    def test_reject_decreases_trust(self, learning_db):
        mgr = AgentTrustManager(db_path=learning_db)
        signal = FeedbackSignal(signal_type=SignalType.REJECT, agent_id="agent_a")
        result = mgr.update_from_signal(signal)
        assert result.trust_score < DEFAULT_TRUST

    def test_respects_floor(self, learning_db):
        mgr = AgentTrustManager(db_path=learning_db)
        for _ in range(100):
            mgr.update_from_signal(FeedbackSignal(signal_type=SignalType.REJECT, agent_id="agent_a"))
        assert mgr.get_trust("agent_a") >= TRUST_FLOOR

    def test_respects_ceiling(self, learning_db):
        mgr = AgentTrustManager(db_path=learning_db)
        for _ in range(100):
            mgr.update_from_signal(FeedbackSignal(signal_type=SignalType.ACCEPT, agent_id="agent_a"))
        assert mgr.get_trust("agent_a") <= TRUST_CEILING

    def test_get_all_scores(self, learning_db):
        mgr = AgentTrustManager(db_path=learning_db)
        mgr.update_from_signal(FeedbackSignal(signal_type=SignalType.ACCEPT, agent_id="a"))
        mgr.update_from_signal(FeedbackSignal(signal_type=SignalType.REJECT, agent_id="b"))
        scores = mgr.get_all_scores()
        assert "a" in scores
        assert "b" in scores


class TestCheckInManager:
    def test_create_persists(self, learning_db):
        mgr = CheckInManager(db_path=learning_db)
        checkin = mgr.create(checkin_type="threshold", prompt="Increase trust?")
        assert checkin.id is not None
        assert checkin.status == CheckInStatus.PENDING

    def test_respond_approves(self, learning_db):
        mgr = CheckInManager(db_path=learning_db)
        checkin = mgr.create(checkin_type="threshold", prompt="Test?")
        result = mgr.respond(checkin.id, approved=True)
        assert result.status == CheckInStatus.APPROVED

    def test_respond_rejects(self, learning_db):
        mgr = CheckInManager(db_path=learning_db)
        checkin = mgr.create(checkin_type="threshold", prompt="Test?")
        result = mgr.respond(checkin.id, approved=False)
        assert result.status == CheckInStatus.REJECTED

    def test_skip(self, learning_db):
        mgr = CheckInManager(db_path=learning_db)
        checkin = mgr.create(checkin_type="threshold", prompt="Test?")
        assert mgr.skip(checkin.id) is True

    def test_get_pending(self, learning_db):
        mgr = CheckInManager(db_path=learning_db)
        mgr.create(checkin_type="threshold", prompt="Pending 1")
        mgr.create(checkin_type="time", prompt="Pending 2")
        pending = mgr.get_pending()
        assert len(pending) == 2

    def test_should_trigger_threshold(self, learning_db):
        mgr = CheckInManager(db_path=learning_db)
        assert mgr.should_trigger("threshold", signal_count=15, threshold=10) is True
        assert mgr.should_trigger("threshold", signal_count=5, threshold=10) is False


class TestUserProfileManager:
    def test_save_and_retrieve_preference(self, learning_db):
        mgr = UserProfileManager(db_path=learning_db)
        pref = UserPreference(
            preference_type="style",
            key="verbosity",
            value="concise",
            source="explicit",
            priority=80,
        )
        saved = mgr.save_preference(pref)
        assert saved.key == "verbosity"

        profile = mgr.get_profile()
        explicit = profile.explicit_preferences
        assert any(p.key == "verbosity" for p in explicit)


# =============================================================================
# VECTOR STORE (fallback mode -- no ChromaDB)
# =============================================================================

from src.{{ project_slug }}.learning.rag.vector_store import VectorStore, SearchResults


class TestVectorStore:
    def test_add_and_count(self):
        store = VectorStore(project_id="test_vs")
        assert store.count == 0
        store.add("d1", "first document", {"tag": "a"})
        assert store.count == 1
        store.add("d2", "second document", {"tag": "b"})
        assert store.count == 2

    def test_upsert_existing_id(self):
        store = VectorStore(project_id="test_vs")
        store.add("d1", "version 1")
        store.add("d1", "version 2")
        assert store.count == 1

    def test_search_keyword_match(self):
        store = VectorStore(project_id="test_vs")
        store.add("d1", "Python programming language")
        store.add("d2", "Java programming language")
        store.add("d3", "French cooking recipes")
        results = store.search("Python programming")
        assert len(results.results) >= 1
        assert results.results[0].id == "d1"

    def test_search_empty_store(self):
        store = VectorStore(project_id="test_vs")
        results = store.search("anything")
        assert results.results == []
        assert results.total == 0

    def test_search_cosine_similarity(self):
        store = VectorStore(project_id="test_vs")
        store.add("d1", "doc one", embedding=[1.0, 0.0, 0.0])
        store.add("d2", "doc two", embedding=[0.0, 1.0, 0.0])
        results = store.search("query", query_embedding=[0.9, 0.1, 0.0])
        assert len(results.results) >= 1
        assert results.results[0].id == "d1"

    def test_delete(self):
        store = VectorStore(project_id="test_vs")
        store.add("d1", "document one")
        store.add("d2", "document two")
        store.delete("d1")
        assert store.count == 1

    def test_clear(self):
        store = VectorStore(project_id="test_vs")
        store.add("d1", "a")
        store.add("d2", "b")
        store.clear()
        assert store.count == 0

    def test_cosine_similarity_identical(self):
        sim = VectorStore._cosine_similarity([1, 0, 0], [1, 0, 0])
        assert abs(sim - 1.0) < 0.001

    def test_cosine_similarity_orthogonal(self):
        sim = VectorStore._cosine_similarity([1, 0, 0], [0, 1, 0])
        assert abs(sim) < 0.001

    def test_cosine_similarity_length_mismatch(self):
        sim = VectorStore._cosine_similarity([1, 0], [1, 0, 0])
        assert sim == 0.0

    def test_cosine_similarity_zero_vector(self):
        sim = VectorStore._cosine_similarity([0, 0, 0], [1, 0, 0])
        assert sim == 0.0

    def test_search_respects_limit(self):
        store = VectorStore(project_id="test_vs")
        for i in range(10):
            store.add(f"d{i}", f"document about topic {i}")
        results = store.search("document topic", limit=3)
        assert len(results.results) <= 3


# =============================================================================
# EMBEDDING SERVICE (fallback mode -- no sentence-transformers/openai)
# =============================================================================

from unittest.mock import MagicMock
from src.{{ project_slug }}.learning.rag.embedding_service import EmbeddingService, EmbeddingResult


class TestEmbeddingService:
    def test_fallback_provider_used(self):
        svc = EmbeddingService()
        assert svc.provider == "fallback"
        assert svc.dimensions == 128

    def test_embed_returns_correct_dimensions(self):
        svc = EmbeddingService()
        result = svc.embed("test text")
        assert len(result.embedding) == 128
        assert result.dimensions == 128
        assert result.provider == "fallback"

    def test_embed_deterministic(self):
        svc = EmbeddingService()
        r1 = svc.embed("same text")
        r2 = svc.embed("same text")
        assert r1.embedding == r2.embedding

    def test_embed_different_texts_differ(self):
        svc = EmbeddingService()
        r1 = svc.embed("text one")
        r2 = svc.embed("text two")
        assert r1.embedding != r2.embedding

    def test_cache_hit(self):
        svc = EmbeddingService()
        r1 = svc.embed("cached text")
        assert r1.cached is False
        r2 = svc.embed("cached text")
        assert r2.cached is True
        assert r1.embedding == r2.embedding

    def test_embed_empty_text(self):
        svc = EmbeddingService()
        result = svc.embed("")
        assert all(v == 0.0 for v in result.embedding)

    def test_embed_batch(self):
        svc = EmbeddingService()
        results = svc.embed_batch(["a", "b", "c"])
        assert len(results) == 3
        assert all(isinstance(r, EmbeddingResult) for r in results)

    def test_embed_local_with_mock(self):
        svc = EmbeddingService()
        svc._provider = "local"
        svc._dimensions = 4
        mock_model = MagicMock()
        mock_array = MagicMock()
        mock_array.tolist.return_value = [0.1, 0.2, 0.3, 0.4]
        mock_model.encode.return_value = mock_array
        svc._model = mock_model
        svc._cache.clear()
        result = svc.embed("test")
        assert len(result.embedding) == 4
        assert result.embedding == [0.1, 0.2, 0.3, 0.4]

    def test_embed_local_fallback_on_error(self):
        svc = EmbeddingService()
        svc._provider = "local"
        svc._dimensions = 128
        mock_model = MagicMock()
        mock_model.encode.side_effect = RuntimeError("model error")
        svc._model = mock_model
        svc._cache.clear()
        result = svc.embed("test")
        assert len(result.embedding) == 128

    def test_embed_openai_with_mock(self):
        svc = EmbeddingService()
        svc._provider = "openai"
        svc._dimensions = 4
        mock_data = MagicMock()
        mock_data.embedding = [0.5, 0.6, 0.7, 0.8]
        mock_resp = MagicMock()
        mock_resp.data = [mock_data]
        mock_client = MagicMock()
        mock_client.embeddings.create.return_value = mock_resp
        svc._openai_client = mock_client
        svc._cache.clear()
        result = svc.embed("test")
        assert result.embedding == [0.5, 0.6, 0.7, 0.8]

    def test_embed_openai_fallback_on_error(self):
        svc = EmbeddingService()
        svc._provider = "openai"
        svc._dimensions = 128
        mock_client = MagicMock()
        mock_client.embeddings.create.side_effect = Exception("API error")
        svc._openai_client = mock_client
        svc._cache.clear()
        result = svc.embed("test")
        assert len(result.embedding) == 128


# =============================================================================
# PREFERENCE RETRIEVER (using fallback services)
# =============================================================================

from src.{{ project_slug }}.learning.rag.preference_retriever import PreferenceRetriever


class TestPreferenceRetriever:
    @pytest.fixture
    def retriever(self, learning_db):
        store = VectorStore(project_id="test_retriever")
        svc = EmbeddingService()
        return PreferenceRetriever(
            project_id="test",
            vector_store=store,
            embedding_service=svc,
            db_path=learning_db,
        )

    def test_index_preference(self, retriever):
        pref = UserPreference(
            preference_type="style", key="verbosity", value="concise",
            source="explicit", priority=80,
        )
        retriever.index_preference(pref)
        assert retriever.indexed_count == 1

    def test_search_returns_results(self, retriever):
        for i, (key, val) in enumerate([
            ("verbosity", "concise responses"),
            ("tone", "professional tone"),
            ("format", "use bullet points"),
        ]):
            retriever.index_preference(UserPreference(
                id=f"pref_{i}", preference_type="style",
                key=key, value=val, source="explicit", priority=70,
            ))
        results = retriever.search("verbose concise", limit=5)
        assert len(results.results) >= 1

    def test_search_min_priority_filter(self, retriever):
        retriever.index_preference(UserPreference(
            id="low", preference_type="style", key="a", value="low priority",
            source="implicit", priority=10,
        ))
        retriever.index_preference(UserPreference(
            id="high", preference_type="style", key="b", value="high priority",
            source="explicit", priority=90,
        ))
        results = retriever.search("priority", min_priority=50)
        for r in results.results:
            assert r.metadata.get("priority", 0) >= 50

    def test_clear_index(self, retriever):
        retriever.index_preference(UserPreference(
            preference_type="style", key="a", value="b",
        ))
        assert retriever.indexed_count == 1
        retriever.clear_index()
        assert retriever.indexed_count == 0

    def test_indexed_count_empty(self, retriever):
        assert retriever.indexed_count == 0


# =============================================================================
# TRANSCRIPT INDEXER (round table transcript search)
# =============================================================================

from src.{{ project_slug }}.learning.rag.transcript_indexer import TranscriptIndexer


class MockAnalysis:
    """Minimal mock for AgentAnalysis."""
    def __init__(self, agent_name, domain, observations=None):
        self.agent_name = agent_name
        self.domain = domain
        self.observations = observations or []
        self.recommendations = []
        self.confidence = 0.8


class MockSynthesis:
    """Minimal mock for SynthesisResult."""
    def __init__(self, recommended_direction=""):
        self.recommended_direction = recommended_direction
        self.key_findings = []
        self.trade_offs = []
        self.minority_views = []


class MockRoundTableResult:
    """Minimal mock for RoundTableResult."""
    def __init__(self, task_id, analyses=None, synthesis=None,
                 consensus_reached=False, duration_seconds=1.0):
        self.task_id = task_id
        self.analyses = analyses or []
        self.synthesis = synthesis
        self.votes = []
        self.consensus_reached = consensus_reached
        self.approval_rate = 1.0 if consensus_reached else 0.0
        self.duration_seconds = duration_seconds


class TestTranscriptIndexer:
    @pytest.fixture
    def indexer(self):
        store = VectorStore(project_id="test_transcripts")
        svc = EmbeddingService()
        return TranscriptIndexer(vector_store=store, embedding_service=svc)

    def test_index_result(self, indexer):
        result = MockRoundTableResult(
            task_id="task_001",
            analyses=[
                MockAnalysis("analyst", "code review", [
                    {"finding": "Found a bug", "evidence": "line 42"},
                ]),
            ],
            synthesis=MockSynthesis("Fix the bug on line 42"),
            consensus_reached=True,
        )
        indexer.index_result(result, task_content="Review the authentication code")
        assert indexer.indexed_count == 1

    def test_search_by_content(self, indexer):
        for i, (task, content) in enumerate([
            ("task_auth", "Review authentication security"),
            ("task_perf", "Analyze database performance bottlenecks"),
            ("task_api", "Design REST API endpoints"),
        ]):
            indexer.index_result(
                MockRoundTableResult(
                    task_id=task,
                    analyses=[MockAnalysis("analyst", "general", [
                        {"finding": content, "evidence": "test"},
                    ])],
                ),
                task_content=content,
            )
        results = indexer.search("authentication security")
        assert len(results.results) >= 1
        task_ids = [r.metadata.get("task_id", "") for r in results.results]
        assert "task_auth" in task_ids

    def test_get_by_task_id(self, indexer):
        indexer.index_result(
            MockRoundTableResult(task_id="lookup_001"),
            task_content="Lookup test task",
        )
        result = indexer.get_by_task_id("lookup_001")
        assert result is not None
        assert result.metadata["task_id"] == "lookup_001"

    def test_search_consensus_only(self, indexer):
        indexer.index_result(
            MockRoundTableResult(task_id="consensus_yes", consensus_reached=True),
            task_content="Agreed on approach",
        )
        indexer.index_result(
            MockRoundTableResult(task_id="consensus_no", consensus_reached=False),
            task_content="Disagreement on approach",
        )
        results = indexer.search("approach", consensus_only=True)
        for r in results.results:
            assert r.metadata.get("consensus_reached") == "True"

    def test_index_empty_result(self, indexer):
        result = MockRoundTableResult(task_id="empty_001")
        indexer.index_result(result, task_content="")
        assert indexer.indexed_count == 0
